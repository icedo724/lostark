import sys
import os
import time
import pandas as pd
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from common.api_client import LostArkAPI
from common.db_connector import get_db_engine


def ensure_data_dir():
    """data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±"""
    data_path = os.path.join(project_root, 'data')
    if not os.path.exists(data_path):
        os.makedirs(data_path)
    return data_path


def update_wide_csv(new_data_list, file_name, current_time_col):
    """
    CSV íŒŒì¼ì— ìƒˆë¡œìš´ ì‹œê°„ ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì—¬ ì €ì¥ (Wide Format)
    :param new_data_list: ìˆ˜ì§‘ëœ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    :param file_name: ì €ì¥í•  íŒŒì¼ëª… (ì˜ˆ: market_materials.csv)
    :param current_time_col: ì»¬ëŸ¼ëª…ì´ ë  ì‹œê°„ ë¬¸ìì—´ (ì˜ˆ: '2026-02-09 21:00')
    """
    data_path = ensure_data_dir()
    full_path = os.path.join(data_path, file_name)

    # 1. ì´ë²ˆì— ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ: ì•„ì´í…œëª…, ê°€ê²©
    current_df = pd.DataFrame(new_data_list)
    if current_df.empty:
        return

    # ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë°©ì§€)
    current_df = current_df.drop_duplicates(subset=['item_name'])

    # ìš°ë¦¬ê°€ í•„ìš”í•œ ê±´ [ì´ë¦„, ê°€ê²©] -> ê°€ê²© ì»¬ëŸ¼ëª…ì„ 'í˜„ì¬ ì‹œê°„'ìœ¼ë¡œ ë³€ê²½
    mini_df = current_df[['item_name', 'current_min_price']].copy()
    mini_df.rename(columns={'current_min_price': current_time_col}, inplace=True)

    # 2. ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë³‘í•©(Merge), ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if os.path.exists(full_path):
        try:
            # ê¸°ì¡´ CSV ì½ê¸°
            old_df = pd.read_csv(full_path)

            # ì•„ì´í…œ ì´ë¦„ì„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© (Outer Join: ìƒˆ ì•„ì´í…œì´ ìƒê²¨ë„ í¬í•¨)
            merged_df = pd.merge(old_df, mini_df, on='item_name', how='outer')

            # ì €ì¥
            merged_df.to_csv(full_path, index=False, encoding='utf-8-sig')
            print(f"   -> ë§ë¶™ì´ê¸° ì„±ê³µ: {file_name} (ì»¬ëŸ¼ ì¶”ê°€: {current_time_col})")
        except Exception as e:
            print(f"   -> CSV ë³‘í•© ì‹¤íŒ¨: {e}")
    else:
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        mini_df.to_csv(full_path, index=False, encoding='utf-8-sig')
        print(f"   -> ì‹ ê·œ ìƒì„±: {file_name}")


def collect_market_data():
    api = LostArkAPI()
    engine = get_db_engine()

    # ì´ë²ˆ ìˆ˜ì§‘ íšŒì°¨ì˜ ê³µí†µ ì‹œê°„ê°’ (CSV ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©)
    # ì—‘ì…€ì—ì„œ ë³´ê¸° í¸í•˜ê²Œ ë¶„ ë‹¨ìœ„ê¹Œì§€ë§Œ í‘œì‹œ
    now_str = datetime.now().strftime('%Y-%m-%d %H:%M')
    print(f"--- [{now_str}] ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ---")

    # ë°ì´í„°ë¥¼ êµ¬ë¶„í•´ì„œ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
    materials_data = []  # ê°•í™”ì¬ë£Œ
    engravings_data = []  # ê°ì¸ì„œ

    # -----------------------------------------------------------
    # [Part 1] ê°•í™” ì¬ë£Œ ìˆ˜ì§‘
    # -----------------------------------------------------------

    # ìˆ˜ì§‘ ëª©ë¡ ì •ì˜
    items_t4 = ["ìš´ëª…ì˜ íŒŒí¸ ì£¼ë¨¸ë‹ˆ(ëŒ€)", "ì•„ë¹„ë„ìŠ¤ ìœµí™” ì¬ë£Œ", "ìš´ëª…ì˜ ëŒíŒŒì„", "ìš´ëª…ì˜ ìˆ˜í˜¸ì„", "ìš´ëª…ì˜ íŒŒê´´ì„", "ë¹™í•˜ì˜ ìˆ¨ê²°", "ìš©ì•”ì˜ ìˆ¨ê²°"]
    items_t3 = ["ëª…ì˜ˆì˜ íŒŒí¸ ì£¼ë¨¸ë‹ˆ(ëŒ€)", "ìµœìƒê¸‰ ì˜¤ë ˆí•˜ ìœµí™” ì¬ë£Œ", "ì°¬ë€í•œ ëª…ì˜ˆì˜ ëŒíŒŒì„", "ì •ì œëœ ìˆ˜í˜¸ê°•ì„", "ì •ì œëœ íŒŒê´´ê°•ì„", "íƒœì–‘ì˜ ì€ì´", "íƒœì–‘ì˜ ì¶•ë³µ", "íƒœì–‘ì˜ ê°€í˜¸"]
    items_special = ["ì¥ì¸ì˜ ì¬ë´‰ìˆ ", "ì¥ì¸ì˜ ì•¼ê¸ˆìˆ "]

    def fetch_materials(item_list, tier_val=None):
        print(f"\nğŸ” ì¬ë£Œ ìˆ˜ì§‘ ì¤‘... (Target: {item_list[0]} ë“±)")
        for name in item_list:
            data = api.get_market_items(category_code=50000, item_name=name, item_tier=tier_val)
            if data and 'Items' in data and len(data['Items']) > 0:
                for item in data['Items']:
                    if name in item['Name']:  # ê²€ìƒ‰ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
                        materials_data.append({
                            'item_name': item['Name'],
                            'item_grade': item['Grade'],
                            'item_tier': tier_val if tier_val else 3,
                            'current_min_price': item['CurrentMinPrice'],
                            'recent_price': item['RecentPrice'],
                            'yday_avg_price': item['YDayAvgPrice'],
                            'bundle_count': item['BundleCount'],
                            'collected_at': datetime.now()
                        })
                        print(f"   -> {item['Name']}: {item['CurrentMinPrice']} G")
            time.sleep(0.15)

    fetch_materials(items_t4, tier_val=4)
    fetch_materials(items_t3, tier_val=3)
    fetch_materials(items_special, tier_val=None)

    # -----------------------------------------------------------
    # [Part 2] ê°ì¸ì„œ ìˆ˜ì§‘
    # -----------------------------------------------------------
    print(f"\nğŸ” [ìœ ë¬¼ ê°ì¸ì„œ] ì „ì²´ ìˆ˜ì§‘ ì¤‘...")
    for page in range(1, 11):
        engraving_data = api.get_market_items(
            category_code=40000, item_grade="ìœ ë¬¼", page_no=page, sort_condition="DESC"
        )
        if engraving_data and 'Items' in engraving_data and len(engraving_data['Items']) > 0:
            for item in engraving_data['Items']:
                engravings_data.append({
                    'item_name': item['Name'],
                    'item_grade': item['Grade'],
                    'item_tier': 3,
                    'current_min_price': item['CurrentMinPrice'],
                    'recent_price': item['RecentPrice'],
                    'yday_avg_price': item['YDayAvgPrice'],
                    'bundle_count': item['BundleCount'],
                    'collected_at': datetime.now()
                })
            print(f"   -> Page {page} ì™„ë£Œ")
            time.sleep(0.2)
        else:
            break

    # -----------------------------------------------------------
    # [Part 3] ë°ì´í„° ì €ì¥ (DB & CSV ë¶„ë¦¬ ì €ì¥)
    # -----------------------------------------------------------

    # 1. DB ì €ì¥ (ê¸°ì¡´ ë°©ì‹ - ì „ì²´ ë°ì´í„°ë¥¼ í•œ í…Œì´ë¸”ì— Append)
    # ë¶„ì„í•  ë•ŒëŠ” DBì˜ Long Formatì´ í›¨ì”¬ ìœ ë¦¬í•˜ë¯€ë¡œ DB êµ¬ì¡°ëŠ” ìœ ì§€í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.
    all_rows = materials_data + engravings_data
    if all_rows and engine:
        try:
            df_db = pd.DataFrame(all_rows)
            df_db.to_sql(name='market_prices', con=engine, if_exists='append', index=False)
            print(f"\nâœ… DB ì €ì¥ ì™„ë£Œ: ì´ {len(df_db)}ê±´")
        except Exception as e:
            print(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")

    # 2. CSV ì €ì¥ (ìš”ì²­ ë°©ì‹ - íŒŒì¼ ë¶„ë¦¬ & ì»¬ëŸ¼ ì¶”ê°€)
    print("\nğŸ“ CSV íŒŒì¼ ì—…ë°ì´íŠ¸ ì¤‘...")

    if materials_data:
        update_wide_csv(materials_data, "market_materials.csv", now_str)

    if engravings_data:
        update_wide_csv(engravings_data, "market_engravings.csv", now_str)

    print("\nğŸ ëª¨ë“  ì‘ì—… ì™„ë£Œ.")


if __name__ == "__main__":
    collect_market_data()